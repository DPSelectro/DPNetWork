{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DPNetwork-Poisson-Autoencoder-USTC-DP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYlxQL-1cOz4",
        "colab_type": "code",
        "outputId": "b224d225-bbd4-4688-86d0-464bddc657ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# This file trains the USTC using differential privacy \n",
        "# by adding nosie to autoencoder first layer \n",
        "# It uses a dense autoencoder. This file enables training \n",
        "# with both l1, l2 noise and both laplacian and gaussian \n",
        "# noise. See the https://arxiv.org/pdf/1802.03471.pdf for \n",
        "# details about how this works. It makes use of privacy amplifcation\n",
        "# by subsampling allowing for less noise to be added\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Bc6CBVrcbCP",
        "colab_type": "code",
        "outputId": "b8e86232-d84c-4ea2-b0a9-c79920b27cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Move to drive\n",
        "%cd drive\n",
        "%cd 'My Drive'\n",
        "%cd Oxford-Thesis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/Oxford-Thesis\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pesGCHF7e1FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import six \n",
        "import math\n",
        "from tensorflow.python.training import moving_averages \n",
        "import pickle\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.preprocessing import normalize\n",
        "import tensorflow_probability as tfp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP0wr4mCcrQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Constants for deciding how to add differential privacy to autoencoder \n",
        "NOISE_PLACEMENT = 'img_noise'\n",
        "NOISE_SCHEME = 'l2'\n",
        "FILTER_SIZES = 1\n",
        "NUM_FILTERS = 1 \n",
        "STRIDES = 1 \n",
        "L1_MEAN_SIGNAL = 0\n",
        "L2_MEAN_SIGNAL = 0\n",
        "L1_NOISE_SIGNAL = 0\n",
        "L2_NOISE_SIGNAL = 0\n",
        "EPSILON = 1.0\n",
        "DELTA_DP = 0.05\n",
        "SCALE = 0.1\n",
        "## BECAUSE WE ARE SUBSAMPLING\n",
        "SACLE = SCALE/2\n",
        "EPOCHS = 40 \n",
        "NOISE = 0\n",
        "BATCH_SHAPE = 256\n",
        "NOISE_TYPE = 'gaussian'\n",
        "AUTO_ENCODER_OUT_SHAPE = 158\n",
        "CONT_FEATURE_SIZE = 158\n",
        "FOLDER = 'USTC2-AutoEncoderGaussianImmedPoisson'\n",
        "NUM_CLASS =10\n",
        "TRAIN =True \n",
        "SCALE_STRING = \"0point1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHJNSA-acjyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## DP-Mult for different types of noise \n",
        "def dp_mult( size=None):\n",
        "  epsilon_dp =EPSILON\n",
        "  delta_dp   = DELTA_DP\n",
        "  max_pixeldp_norm = SCALE\n",
        "  if NOISE_SCHEME == 'l1_l2'    or  \\\n",
        "      NOISE_SCHEME == 'l1_l2_s1' or  \\\n",
        "      NOISE_SCHEME == 'l2_l2_s1' or\\\n",
        "      NOISE_SCHEME == 'l2':\n",
        "      return max_pixeldp_norm * \\\n",
        "          math.sqrt(2 * math.log(1.25 / delta_dp)) / epsilon_dp\n",
        "  elif NOISE_SCHEME == 'l1_l1'  or  \\\n",
        "      NOISE_SCHEME == 'l1_l1_s1' or\\\n",
        "      NOISE_SCHEME == 'l1':\n",
        "      return max_pixeldp_norm / epsilon_dp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5eOoT0sclC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Create different types of noises for different \n",
        "## noise types and schemes\n",
        "def img_dp_noise(shape):\n",
        "  if NOISE_TYPE == 'laplace':\n",
        "    sensitivity_multiplier = EPSILON \n",
        "    dp_mult_x = dp_mult()\n",
        "    loc = tf.zeros([BATCH_SHAPE,shape])\n",
        "    scale = tf.ones([BATCH_SHAPE,shape])\n",
        "    epsilon = tfp.distributions.Laplace(loc,scale).sample()\n",
        "    noise_scale = tf.placeholder(tf.float32,shape =(), name ='noise_scale')\n",
        "    L1_SENSITIVITY = 1.0\n",
        "    b = L1_SENSITIVITY *dp_mult_x*SCALE\n",
        "    noise = b *epsilon\n",
        "    \n",
        "  elif NOISE_TYPE == 'gaussian':\n",
        "    dp_mult_x = dp_mult()\n",
        "    epsilon = tf.random_normal(shape=(BATCH_SHAPE,shape), mean=0,stddev=1)\n",
        "    sensitivity_multiplier = EPSILON \n",
        "    L2_SENSITIVITY = 1.0\n",
        "    noise_scale = tf.placeholder(tf.float32,shape =(), name ='noise_scale')\n",
        "    SIGMA = tf.multiply(dp_mult_x,L2_SENSITIVITY,name= \"SIGMA\")\n",
        "    noise_stddev = SCALE * SIGMA\n",
        "    noise = noise_stddev *epsilon\n",
        "  return noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GaeWsv0cmNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the l1 direction https://github.com/columbia/pixeldp\n",
        "def l1_normalize(x, dim, epsilon=1e-12, name=None):\n",
        "  \"\"\"Normalizes along dimension `dim` using an L1 norm.\n",
        "  For a 1-D tensor with `dim = 0`, computes\n",
        "      output = x / max(sum(abs(x)), epsilon)\n",
        "  For `x` with more dimensions, independently normalizes each 1-D slice along\n",
        "  dimension `dim`.\n",
        "  Args:\n",
        "    x: A `Tensor`.\n",
        "    dim: Dimension along which to normalize.  A scalar or a vector of\n",
        "      integers.\n",
        "    epsilon: A lower bound value for the norm. Will use `sqrt(epsilon)` as the\n",
        "      divisor if `norm < sqrt(epsilon)`.\n",
        "    name: A name for this operation (optional).\n",
        "  Returns:\n",
        "    A `Tensor` with the same shape as `x`.\n",
        "  \"\"\"\n",
        "  with tf.name_scope(name, \"l1_normalize\", [x]) as name:\n",
        "    with tf.device(\"/gpu:0\"):\n",
        "      x          = tf.convert_to_tensor(x, name            = \"x\")\n",
        "      abs_sum    = tf.reduce_sum(tf.abs(x), dim, keep_dims = True)\n",
        "      x_inv_norm = tf.reciprocal(tf.maximum(abs_sum, epsilon))\n",
        "      return tf.multiply(x, x_inv_norm, name=name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqzxucIAcnsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  NOISE = img_dp_noise(int(CONT_FEATURE_SIZE))\n",
        "  ## Define the auto encoder without keras \n",
        "  x_ = tf.placeholder(tf.float32,shape= [BATCH_SHAPE,CONT_FEATURE_SIZE])\n",
        "  y_ =tf.placeholder(tf.float32,shape= [BATCH_SHAPE,CONT_FEATURE_SIZE])\n",
        "  \n",
        "  x2_ =tf.placeholder(tf.float32,shape= [BATCH_SHAPE,AUTO_ENCODER_OUT_SHAPE])\n",
        "  y2_ =tf.placeholder(tf.float32,shape= [BATCH_SHAPE,2])\n",
        "  y3_ =tf.placeholder(tf.float32,shape= [BATCH_SHAPE,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MBcctJ5c5Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rep(x, full_rep = True):\n",
        "  with tf.variable_scope(\"first_model\",reuse=tf.AUTO_REUSE):\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      if TRAIN == True:\n",
        "        noise_image = tf.add(x,NOISE)\n",
        "      else:\n",
        "        noise_image = tf.add(x,img_dp_noise(CONT_FEATURE_SIZE))\n",
        "      ## ADD NOISE \n",
        "      W_dense1 = tf.get_variable(\"dense1\",initializer =tf.random_normal(stddev=0.1, shape =[CONT_FEATURE_SIZE,int(CONT_FEATURE_SIZE/2)]))\n",
        "      b_dense1 =  tf.get_variable(\"bias1\",initializer =tf.random_normal(stddev=0.1, shape =[int(CONT_FEATURE_SIZE/2)]))\n",
        "      h_fc1 = tf.nn.relu(tf.matmul(tf.cast(noise_image,tf.float32),W_dense1)+b_dense1)\n",
        "      \n",
        "      W_dense2 =tf.get_variable(\"dense2\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/2),int(CONT_FEATURE_SIZE/4)]))\n",
        "      b_dense2 = tf.get_variable(\"bias2\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/4)]))\n",
        "      h_fc2 = tf.nn.relu(tf.matmul(h_fc1, W_dense2) + b_dense2)\n",
        "\n",
        "\n",
        "      W_dense3 =tf.get_variable(\"dense3\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/4),10]))\n",
        "      b_dense3 =tf.get_variable(\"bias3\",initializer =tf.random_normal(stddev=0.1,shape= [10])) \n",
        "      first_output = tf.matmul(h_fc2, W_dense3) + b_dense3\n",
        "      h_fc3 = tf.nn.relu(first_output)\n",
        "\n",
        "      W_dense4 =tf.get_variable(\"dense4\",initializer =tf.random_normal(stddev=0.1,shape= [10,int(CONT_FEATURE_SIZE/4)]))\n",
        "      b_dense4 =tf.get_variable(\"bias4\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/4)]))\n",
        "      h_fc4 = tf.nn.relu(tf.matmul(h_fc3, W_dense4) + b_dense4)\n",
        "\n",
        "      W_dense5 = tf.get_variable(\"dense5\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/4),int(CONT_FEATURE_SIZE/2)]))\n",
        "      b_dense5 = tf.get_variable(\"bias5\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/2)]))\n",
        "      h_fc5 = tf.nn.relu(tf.matmul(h_fc4, W_dense5) + b_dense5)\n",
        "\n",
        "      W_dense6 = tf.get_variable(\"dense6\",initializer =tf.random_normal(stddev=0.1,shape= [int(CONT_FEATURE_SIZE/2),int(CONT_FEATURE_SIZE)]))\n",
        "      b_dense6 = tf.get_variable(\"bias6\",initializer =tf.random_normal(stddev=0.1,shape= [CONT_FEATURE_SIZE]))\n",
        "      h_fc6 = tf.matmul(h_fc5, W_dense6) + b_dense6\n",
        "      if full_rep == True:\n",
        "        return h_fc6\n",
        "      return first_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-Vu_9KdGMB",
        "colab_type": "code",
        "outputId": "68beb0da-0494-4b31-edec-b54fbb3856ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  mse = tf.reduce_mean(tf.losses.mean_squared_error(labels=y_, predictions=get_rep(x_,True)))\n",
        "  train_step = tf.train.AdamOptimizer(1e-4,name=\"adam-encoder\").minimize(mse)\n",
        "  accuracy = mse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 19:06:20.060935 139962619545472 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xkfVUL8dKUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "## Load in data\n",
        "with open('./embedding/CNN_FULL/USTC_prn_mal_meta_train', 'rb') as fp:\n",
        "  mal_train_meta_X = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n",
        "with open('./embedding/CNN_FULL/USTC_prn_mal_meta_valid', 'rb') as fp:\n",
        "  mal_valid_meta_X = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n",
        "  \n",
        "with open('./embedding/CNN_FULL/USTC_prn_mal_meta_train_labels', 'rb') as fp:\n",
        "  mal_train_labels = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n",
        "with open('./embedding/CNN_FULL/USTC_prn_mal_meta_valid_labels', 'rb') as fp:\n",
        "  mal_valid_labels = pickle.load(fp) \n",
        "  fp.close()\n",
        "  \n",
        "\n",
        "with open('./embedding/CNN_FULL/USTC_prn_benign_meta_train', 'rb') as fp:\n",
        "  benign_train_meta_X = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n",
        "with open('./embedding/CNN_FULL/USTC_prn_benign_meta_valid', 'rb') as fp:\n",
        "  benign_valid_meta_X  = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n",
        "with open('./embedding/CNN_FULL/USTC_prn_benign_size_train', 'rb') as fp:\n",
        "  benign_train_size_X = pickle.load(fp)\n",
        "  fp.close()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-HmlKeIo76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = [[0,1]]*len(benign_train_meta_X) +[[1,0]]*len(mal_train_meta_X)\n",
        "valid_labels = [[0,1]]*len(benign_valid_meta_X) +[[1,0]]*len(mal_valid_meta_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLemEbpqoFor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_meta_X = np.concatenate([benign_train_meta_X,mal_train_meta_X])\n",
        "valid_meta_X = np.concatenate([benign_valid_meta_X,mal_valid_meta_X])\n",
        "\n",
        "c = list(zip(train_meta_X,train_labels))\n",
        "np.random.shuffle(c)\n",
        "train_meta_X,train_labels = zip(*c)\n",
        "\n",
        "c = list(zip(valid_meta_X,valid_labels))\n",
        "np.random.shuffle(c)\n",
        "valid_meta_X,valid_labels = zip(*c)\n",
        "train_meta_X = np.array(train_meta_X).astype(float)\n",
        "valid_meta_X = np.array(valid_meta_X).astype(float)\n",
        "valid_meta_X = valid_meta_X[:52992]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPYAE3eBJnU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X =np.array(train_meta_X).astype(float)\n",
        "## Subsample with lambda = 0.5 \n",
        "samples = []\n",
        "probs = np.random.uniform(size=len(train_X))\n",
        "for index in range(len(probs)):\n",
        "  if probs[index]<= 0.5:\n",
        "    samples.append(train_X[index])\n",
        "train_X = np.array(samples).astype(float)\n",
        "valid_X =np.array(valid_meta_X).astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMX0jmiQC5wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_X)/256\n",
        "amount = int(len(train_X)/256)*256\n",
        "train_X=train_X[:amount]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQlrF9QgAD9",
        "colab_type": "code",
        "outputId": "5c529a69-78a5-415e-ee28-4bba0c1d3963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Available:  True\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRY6751OffNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session = tf.Session(config=config)\n",
        "session.run(tf.global_variables_initializer())\n",
        "with session as sess:\n",
        "  noise = sess.run(NOISE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS6XD81rggKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./DP-GRAPHS/' + FOLDER +'/NOISE'+SCALE_STRING, 'wb') as fp:\n",
        "  pickle.dump(noise,fp)\n",
        "  fp.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cHwyMCAhfZ_k",
        "outputId": "6f19e417-a40f-4d11-e125-61e220856c97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the autoencoder\n",
        "EPOCHS = 60\n",
        "session = tf.Session(config=config)\n",
        "session.run(tf.global_variables_initializer())\n",
        "x_coord = 0\n",
        "x_coords = []\n",
        "mses = []\n",
        "with session as sess:\n",
        "  for epoch in range(EPOCHS):\n",
        "    train_accuracy = 0 \n",
        "    for batch_num in range(int(len(train_X)/BATCH_SHAPE)):\n",
        "      batch = train_X[batch_num*BATCH_SHAPE:batch_num*BATCH_SHAPE+BATCH_SHAPE]\n",
        "      batch_label = train_X[batch_num*BATCH_SHAPE:batch_num*BATCH_SHAPE+BATCH_SHAPE]\n",
        "      train_accuracy += accuracy.eval(feed_dict={x_:batch, y_: batch_label})\n",
        "      train_step.run(feed_dict={x_: batch, y_: batch_label})\n",
        "    x_coords.append(x_coord)\n",
        "    x_coord+=1\n",
        "    mses.append(train_accuracy/(int(len(train_X)/BATCH_SHAPE)))\n",
        "    print('Step %d, training accuracy %g' % (batch_num , train_accuracy/(int(len(train_X)/BATCH_SHAPE))))\n",
        "    valid_acc = 0 \n",
        "    for batch_num in range(int(len(valid_X)/BATCH_SHAPE)): \n",
        "      batch = valid_X[batch_num*BATCH_SHAPE:batch_num*BATCH_SHAPE+BATCH_SHAPE]\n",
        "      batch_label = valid_X[batch_num*BATCH_SHAPE:batch_num*BATCH_SHAPE+BATCH_SHAPE]\n",
        "      valid_acc += accuracy.eval(feed_dict={x_:batch, y_: batch_label})\n",
        "    print('Step %d, validation accuracy %g' % (batch_num , valid_acc/(int(len(valid_X)/BATCH_SHAPE)))) \n",
        "  saver.save(sess, './DP-GRAPHS/' + FOLDER+ '/poisson-autoencoder'+SCALE_STRING+'.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1271, training accuracy 0.0130174\n",
            "Step 206, validation accuracy 0.00272938\n",
            "Step 1271, training accuracy 0.00179892\n",
            "Step 206, validation accuracy 0.000898205\n",
            "Step 1271, training accuracy 0.000983687\n",
            "Step 206, validation accuracy 0.000627942\n",
            "Step 1271, training accuracy 0.000726486\n",
            "Step 206, validation accuracy 0.000463065\n",
            "Step 1271, training accuracy 0.0005209\n",
            "Step 206, validation accuracy 0.000344177\n",
            "Step 1271, training accuracy 0.000409227\n",
            "Step 206, validation accuracy 0.000286768\n",
            "Step 1271, training accuracy 0.000357417\n",
            "Step 206, validation accuracy 0.000256944\n",
            "Step 1271, training accuracy 0.000329049\n",
            "Step 206, validation accuracy 0.000239366\n",
            "Step 1271, training accuracy 0.000310018\n",
            "Step 206, validation accuracy 0.000225716\n",
            "Step 1271, training accuracy 0.000293409\n",
            "Step 206, validation accuracy 0.000212955\n",
            "Step 1271, training accuracy 0.00027766\n",
            "Step 206, validation accuracy 0.000200518\n",
            "Step 1271, training accuracy 0.000262272\n",
            "Step 206, validation accuracy 0.000188771\n",
            "Step 1271, training accuracy 0.000247817\n",
            "Step 206, validation accuracy 0.000177915\n",
            "Step 1271, training accuracy 0.000234378\n",
            "Step 206, validation accuracy 0.000167739\n",
            "Step 1271, training accuracy 0.00022191\n",
            "Step 206, validation accuracy 0.000158418\n",
            "Step 1271, training accuracy 0.000209474\n",
            "Step 206, validation accuracy 0.000149168\n",
            "Step 1271, training accuracy 0.000196614\n",
            "Step 206, validation accuracy 0.000141335\n",
            "Step 1271, training accuracy 0.00018675\n",
            "Step 206, validation accuracy 0.00013518\n",
            "Step 1271, training accuracy 0.000178879\n",
            "Step 206, validation accuracy 0.000129706\n",
            "Step 1271, training accuracy 0.000172139\n",
            "Step 206, validation accuracy 0.000125036\n",
            "Step 1271, training accuracy 0.000166339\n",
            "Step 206, validation accuracy 0.000120923\n",
            "Step 1271, training accuracy 0.000161174\n",
            "Step 206, validation accuracy 0.000117271\n",
            "Step 1271, training accuracy 0.000156472\n",
            "Step 206, validation accuracy 0.000113877\n",
            "Step 1271, training accuracy 0.000152114\n",
            "Step 206, validation accuracy 0.000110973\n",
            "Step 1271, training accuracy 0.000148079\n",
            "Step 206, validation accuracy 0.000108122\n",
            "Step 1271, training accuracy 0.000144309\n",
            "Step 206, validation accuracy 0.000105587\n",
            "Step 1271, training accuracy 0.000140794\n",
            "Step 206, validation accuracy 0.000103191\n",
            "Step 1271, training accuracy 0.00013745\n",
            "Step 206, validation accuracy 0.000100886\n",
            "Step 1271, training accuracy 0.000134301\n",
            "Step 206, validation accuracy 9.87539e-05\n",
            "Step 1271, training accuracy 0.000131265\n",
            "Step 206, validation accuracy 9.66245e-05\n",
            "Step 1271, training accuracy 0.000128352\n",
            "Step 206, validation accuracy 9.47949e-05\n",
            "Step 1271, training accuracy 0.00012563\n",
            "Step 206, validation accuracy 9.30319e-05\n",
            "Step 1271, training accuracy 0.000123046\n",
            "Step 206, validation accuracy 9.13141e-05\n",
            "Step 1271, training accuracy 0.000120549\n",
            "Step 206, validation accuracy 8.96998e-05\n",
            "Step 1271, training accuracy 0.000118184\n",
            "Step 206, validation accuracy 8.81711e-05\n",
            "Step 1271, training accuracy 0.000115898\n",
            "Step 206, validation accuracy 8.66892e-05\n",
            "Step 1271, training accuracy 0.000113674\n",
            "Step 206, validation accuracy 8.52485e-05\n",
            "Step 1271, training accuracy 0.000111502\n",
            "Step 206, validation accuracy 8.38193e-05\n",
            "Step 1271, training accuracy 0.000109479\n",
            "Step 206, validation accuracy 8.24961e-05\n",
            "Step 1271, training accuracy 0.000107596\n",
            "Step 206, validation accuracy 8.13168e-05\n",
            "Step 1271, training accuracy 0.000105814\n",
            "Step 206, validation accuracy 8.02043e-05\n",
            "Step 1271, training accuracy 0.000104101\n",
            "Step 206, validation accuracy 7.88935e-05\n",
            "Step 1271, training accuracy 0.000102256\n",
            "Step 206, validation accuracy 7.78056e-05\n",
            "Step 1271, training accuracy 0.000100605\n",
            "Step 206, validation accuracy 7.67408e-05\n",
            "Step 1271, training accuracy 9.9039e-05\n",
            "Step 206, validation accuracy 7.57728e-05\n",
            "Step 1271, training accuracy 9.75319e-05\n",
            "Step 206, validation accuracy 7.47989e-05\n",
            "Step 1271, training accuracy 9.60947e-05\n",
            "Step 206, validation accuracy 7.38505e-05\n",
            "Step 1271, training accuracy 9.47016e-05\n",
            "Step 206, validation accuracy 7.29283e-05\n",
            "Step 1271, training accuracy 9.33918e-05\n",
            "Step 206, validation accuracy 7.20491e-05\n",
            "Step 1271, training accuracy 9.21466e-05\n",
            "Step 206, validation accuracy 7.12133e-05\n",
            "Step 1271, training accuracy 9.09685e-05\n",
            "Step 206, validation accuracy 7.04168e-05\n",
            "Step 1271, training accuracy 8.98339e-05\n",
            "Step 206, validation accuracy 6.96109e-05\n",
            "Step 1271, training accuracy 8.87478e-05\n",
            "Step 206, validation accuracy 6.88706e-05\n",
            "Step 1271, training accuracy 8.77197e-05\n",
            "Step 206, validation accuracy 6.81669e-05\n",
            "Step 1271, training accuracy 8.67295e-05\n",
            "Step 206, validation accuracy 6.74875e-05\n",
            "Step 1271, training accuracy 8.5771e-05\n",
            "Step 206, validation accuracy 6.67899e-05\n",
            "Step 1271, training accuracy 8.47787e-05\n",
            "Step 206, validation accuracy 6.61059e-05\n",
            "Step 1271, training accuracy 8.38787e-05\n",
            "Step 206, validation accuracy 6.54342e-05\n",
            "Step 1271, training accuracy 8.30086e-05\n",
            "Step 206, validation accuracy 6.4835e-05\n",
            "Step 1271, training accuracy 8.2204e-05\n",
            "Step 206, validation accuracy 6.42646e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rocUZquyfbbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}